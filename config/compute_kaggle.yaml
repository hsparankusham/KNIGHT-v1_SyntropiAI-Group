# =============================================================================
# KNIGHT v1 â€” Kaggle T4 GPU compute profile
# =============================================================================
# Kaggle free tier: 1x T4 (16 GB VRAM), 16 GB RAM, 30 hrs/week
#
# Usage: Override defaults.yaml for Kaggle notebook training.
#   python scripts/training/01_pretrain_knight_min.py --config config/compute_kaggle.yaml

model:
  # Use KNIGHT-min on Kaggle T4 (full scGPT backbone needs >16 GB)
  use_variant: "knight_min"

training:
  pretraining:
    epochs: 50
    batch_size: 32              # T4 16GB fits ~32 with KNIGHT-min (d=256)
    lr: 1.0e-4
    warmup_steps: 2000
    weight_decay: 0.01
    mask_ratio: 0.15
    max_grad_norm: 1.0

  finetuning:
    epochs: 30
    batch_size: 32
    lr: 5.0e-5
    patience: 10

  optimizer: "adamw"
  scheduler: "cosine_warmup"
  fp16: true                    # T4 has good fp16 support
  gradient_accumulation_steps: 4  # Effective batch = 32 * 4 = 128

compute:
  gpus: 1
  gpu_type: "t4_16gb"
  num_workers: 2                # Kaggle has 4 CPU cores
  pin_memory: true
  device: "cuda"

wandb:
  project: "knight-v1"
  entity: "syntropi-ai"
  # Set WANDB_API_KEY in Kaggle secrets before training
